{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "description: Validates the employed methods in the previous sections to discard them as causes of the poor results.\n",
    "code-tools:\n",
    "  toggle: true\n",
    "format:\n",
    "  html:\n",
    "    code-links:\n",
    "      - binder\n",
    "      - text: Python functions\n",
    "        icon: file-code\n",
    "        href: https://github.com/matey97/thesis/blob/main/libs/chapter5/analysis\n",
    "        target: blank\n",
    "jupyter: python\n",
    "---  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of employed methods {#sec-methods_validation}\n",
    "\n",
    "This section validates the employed methods (i.e., data preparation and DL model) on public datasets and uses another method presented in the literature on the collected dataset. This aims to confirm or discard the identified factor (1) as the cause of the poor results in @sec-localized_har."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from libs.chapter5.analysis.reports import metrics_summary, metric_increment_summary\n",
    "from libs.common.utils import load_json\n",
    "\n",
    "REPORTS_DIR = os.path.join('data', 'chapter5', 'model-reports')\n",
    "REPORTS_FILE = '{}_report.json'\n",
    "CHOI_REPORTS_PATH = os.path.join(REPORTS_DIR, 'preliminar-dataset', 'choi-method')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation on public datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@tbl-validation_datasets shows the average accuracies, precisions, recalls, and F1-scores of the cross-validation procedure obtained by the selected CNN model in the two described public datasets.\n",
    "\n",
    "The results of the model in the StanWiFi dataset are around $96\\%$ in all metrics. These results are better than the ones presented by the creators of the database [@yousefi2017survey], but slightly worse than other proposed solutions in the literature.\n",
    "\n",
    "Regarding the Multienvironment datasets (`E1` and `E2`), the model obtains significantly worse results than other works in the literature. These results can be explained due to the higher complexity of the dataset compared with StanWiFi and the collected dataset. In addition, the employed model is an adaptation from the previous section and it is not optimized for this dataset, whereas other works completely focus on this dataset and use more complex methods such as specific feature extraction, adaptative windows, or windowing approaches with an excessive overlapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>StanWiFi CV</th>\n",
       "      <td>0.962032</td>\n",
       "      <td>0.963551</td>\n",
       "      <td>0.962032</td>\n",
       "      <td>0.961797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multienvironment E1</th>\n",
       "      <td>0.830443</td>\n",
       "      <td>0.871437</td>\n",
       "      <td>0.830443</td>\n",
       "      <td>0.832676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multienvironment E2</th>\n",
       "      <td>0.789978</td>\n",
       "      <td>0.821395</td>\n",
       "      <td>0.789978</td>\n",
       "      <td>0.783325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Precision    Recall  F1-score\n",
       "StanWiFi CV          0.962032   0.963551  0.962032  0.961797\n",
       "Multienvironment E1  0.830443   0.871437  0.830443  0.832676\n",
       "Multienvironment E2  0.789978   0.821395  0.789978  0.783325"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-validation_datasets\n",
    "#| tbl-cap: \"Results of applying the proposed method on the StanWiFi and Multienvironment `E1` and `E2` datasets.\"\n",
    "\n",
    "stanwifi_reports = load_json(os.path.join(REPORTS_DIR, 'stanwifi', REPORTS_FILE.format('cv')))\n",
    "e1_reports = load_json(os.path.join(REPORTS_DIR, 'multienvironment', REPORTS_FILE.format('e1-cv')))\n",
    "e2_reports = load_json(os.path.join(REPORTS_DIR, 'multienvironment', REPORTS_FILE.format('e2-cv')))\n",
    "metrics_summary([stanwifi_reports, e1_reports, e2_reports], ['StanWiFi CV', 'Multienvironment E1', 'Multienvironment E2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, these results show that while the employed methods and model do not improve the existing results in the literature, neither does it completely fail in its classification purpose. In addition, the model could yield more satisfactory results after a proper optimization for both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of other method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@tbl-choi_metrics_summary contains the accuracy, precision, recall and F1-score metrics obtained in each evaluation approach and @tbl-choi_metrics_decrement include the relative decrement in each metric regarding the first evaluation approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CV</th>\n",
       "      <td>0.898863</td>\n",
       "      <td>0.914035</td>\n",
       "      <td>0.898863</td>\n",
       "      <td>0.890320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1T/D1E</th>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.875248</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.845221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1T/D2</th>\n",
       "      <td>0.259615</td>\n",
       "      <td>0.305082</td>\n",
       "      <td>0.259615</td>\n",
       "      <td>0.253803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1T/D3</th>\n",
       "      <td>0.284314</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.284314</td>\n",
       "      <td>0.234527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1T/D4</th>\n",
       "      <td>0.112245</td>\n",
       "      <td>0.112294</td>\n",
       "      <td>0.112245</td>\n",
       "      <td>0.082696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Accuracy  Precision    Recall  F1-score\n",
       "CV       0.898863   0.914035  0.898863  0.890320\n",
       "D1T/D1E  0.841584   0.875248  0.841584  0.845221\n",
       "D1T/D2   0.259615   0.305082  0.259615  0.253803\n",
       "D1T/D3   0.284314   0.254167  0.284314  0.234527\n",
       "D1T/D4   0.112245   0.112294  0.112245  0.082696"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-choi_metrics_summary\n",
    "#| tbl-cap: \"Summary of obtained metrics in the evaluation approaches using Choi's method.\"\n",
    "\n",
    "\n",
    "choi_cv_report = load_json(os.path.join(CHOI_REPORTS_PATH, REPORTS_FILE.format('cv')))\n",
    "choi_d1_report = load_json(os.path.join(CHOI_REPORTS_PATH, REPORTS_FILE.format('d1')))\n",
    "choi_d2_report = load_json(os.path.join(CHOI_REPORTS_PATH, REPORTS_FILE.format('d2')))\n",
    "choi_d3_report = load_json(os.path.join(CHOI_REPORTS_PATH, REPORTS_FILE.format('d3')))\n",
    "choi_d4_report = load_json(os.path.join(CHOI_REPORTS_PATH, REPORTS_FILE.format('d4')))\n",
    "\n",
    "metrics_summary([choi_cv_report, choi_d1_report, choi_d2_report, choi_d3_report, choi_d4_report], ['CV', 'D1T/D1E', 'D1T/D2', 'D1T/D3', 'D1T/D4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the $10$-fold cross-validation approach, Choi's method achieves better results than the one employed in the previous section, around three percentual points in all metrics.\n",
    "\n",
    "Regarding the `D1T/D1E` evaluation, both methods obtain similar outcomes around $\\approx 84\\%$ in all metric except in Choi's method precision, which is two percentual points better than the other method.\n",
    "\n",
    "However, Choi's method fails when taking into account the effect of time. In the `D1T/D2`, `D1T/D3`, `D1T/D4` evaluations, the obtained results are much worse than the ones presented previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CV vs. D1T/D1E</th>\n",
       "      <td>-6.372340</td>\n",
       "      <td>-4.243565</td>\n",
       "      <td>-6.372340</td>\n",
       "      <td>-5.065488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV vs. D1T/D2</th>\n",
       "      <td>-71.117350</td>\n",
       "      <td>-66.622465</td>\n",
       "      <td>-71.117350</td>\n",
       "      <td>-71.493068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV vs. D1T/D3</th>\n",
       "      <td>-68.369617</td>\n",
       "      <td>-72.192902</td>\n",
       "      <td>-68.369617</td>\n",
       "      <td>-73.658177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV vs. D1T/D4</th>\n",
       "      <td>-87.512565</td>\n",
       "      <td>-87.714499</td>\n",
       "      <td>-87.512565</td>\n",
       "      <td>-90.711641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Accuracy  Precision     Recall   F1-score\n",
       "CV vs. D1T/D1E  -6.372340  -4.243565  -6.372340  -5.065488\n",
       "CV vs. D1T/D2  -71.117350 -66.622465 -71.117350 -71.493068\n",
       "CV vs. D1T/D3  -68.369617 -72.192902 -68.369617 -73.658177\n",
       "CV vs. D1T/D4  -87.512565 -87.714499 -87.512565 -90.711641"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| label: tbl-choi_metrics_decrement\n",
    "#| tbl-cap: \"Decrement (%) of metrics in the evaluation approaches using Choi's method.\"\n",
    "\n",
    "comparisons = {\n",
    "    'CV vs. D1T/D1E': [choi_cv_report, choi_d1_report],\n",
    "    'CV vs. D1T/D2': [choi_cv_report, choi_d2_report],\n",
    "    'CV vs. D1T/D3': [choi_cv_report, choi_d3_report],\n",
    "    'CV vs. D1T/D4': [choi_cv_report, choi_d4_report],\n",
    "}\n",
    "display(metric_increment_summary(comparisons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results obtained in the previous sections, we can determine that the employed methods and model -- factor (1) -- are not the cause of the bad results obtained in @sec-localized_har since 1) the methods and model obtained acceptable results in other public datasets and 2) a validated method in the literature also obtained very poor results with the collected datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code reference\n",
    "\n",
    "::: {.callout-tip}\n",
    "The documentation of the Python functions employed in this section can be found in\n",
    " [Chapter 5 reference](reference/index.qmd#chapter-5):\n",
    "\n",
    "- [`reports`](reference/chapter5.analysis.reports.qmd):\n",
    "  - [`metrics_summary`](reference/chapter5.analysis.reports.qmd#libs.chapter5.analysis.reports.metrics_summary)\n",
    "  - [`metric_increment_summary`](reference/chapter5.analysis.reports.qmd#libs.chapter5.analysis.reports.metric_increment_summary)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
